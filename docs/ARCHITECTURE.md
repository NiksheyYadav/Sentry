# System Architecture

Technical overview of Sentry's multimodal mental health assessment pipeline.

---

## Table of Contents

1. [Pipeline Overview](#1-pipeline-overview)
2. [Facial Analysis](#2-facial-analysis)
3. [Posture Analysis](#3-posture-analysis)
4. [Fusion Engine](#4-fusion-engine)
5. [Prediction Heads](#5-prediction-heads)
6. [File Structure](#6-file-structure)

---

## 1. Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VIDEO INPUT (30 FPS)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FACIAL BRANCH       â”‚     â”‚     POSTURE BRANCH      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. MTCNN Face Detection â”‚     â”‚ 1. MediaPipe Pose       â”‚
â”‚ 2. Lighting Normalize   â”‚     â”‚ 2. Feature Extraction   â”‚
â”‚ 3. DenseNet121 Backbone â”‚     â”‚    (15 features)        â”‚
â”‚ 4. Emotion Classificationâ”‚    â”‚ 3. TCN Encoder          â”‚
â”‚ 5. 512D Embedding       â”‚     â”‚ 4. LSTM Temporal        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ 5. 512D Embedding       â”‚
              â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       FUSION ENGINE             â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ â€¢ Cross-Attention (8 heads)     â”‚
              â”‚ â€¢ Feature Concatenation         â”‚
              â”‚ â€¢ 1024D Fused Embedding         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     MENTAL HEALTH CLASSIFIER    â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ Shared Backbone (512D)          â”‚
              â”‚         â”‚                       â”‚
              â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”   â”‚
              â”‚    â–¼    â–¼    â–¼    â–¼    â–¼    â–¼   â”‚
              â”‚ Stress Dep. Anx. Post.Stress Trajâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Facial Analysis

### Face Detection: MTCNN

Multi-task Cascaded Convolutional Networks for robust face detection.

| Stage | Purpose |
|-------|---------|
| P-Net | Proposal generation |
| R-Net | Refine bounding boxes |
| O-Net | Final detection + landmarks |

### Emotion Classification: DenseNet121

**Architecture:**
- Backbone: DenseNet121 (pre-trained on ImageNet)
- Modified: First conv layer accepts 1-channel grayscale
- Output: 6-class emotion + 512D embedding

**Preprocessing Pipeline:**
1. Convert to PIL Image
2. **Lighting Normalization** (CLAHE + adaptive gamma correction for low-light)
3. Resize to 224Ã—224
4. Normalize (mean=0.5, std=0.5)

**Input:** 224Ã—224 grayscale image (lighting-normalized)  
**Output:** `(emotion_logits, embedding)`

**Source:** `src/facial/emotion.py`

### FaceMesh Expression Analysis

MediaPipe FaceMesh provides 468 facial landmarks for precise expression detection.

**Used For:**
- Expression validation (smile, surprise, frown detection)
- Emotion post-processing corrections
- Real-time meshgrid visualization

**Expression Features:**
| Feature | Landmarks Used | Purpose |
|---------|----------------|---------|
| Eye Aspect Ratio (EAR) | 6 points per eye | Blink/openness detection |
| Eyebrow Raise | 10 points per brow | Surprise/fear detection |
| Mouth Openness | Lip landmarks | Surprise/speech detection |
| Smile Score | Mouth corners | Happy detection |

**Visualization Colors:**
- ğŸŸ¢ **Eyes** (green) - Tracks openness
- ğŸ”µ **Eyebrows** (blue) - Tracks raising
- ğŸŸ£ **Lips** (magenta) - Tracks smiles
- ğŸŸ  **Face contour** (orange) - Tracks jaw

**Source:** `src/facial/facemesh_analyzer.py`, `src/visualization/facemesh_visualizer.py`

---

## 3. Posture Analysis

### Pose Estimation: MediaPipe

Extracts 33 body landmarks in real-time.

### Feature Extraction

From landmarks, we compute **15 features**:

| Category | Features |
|----------|----------|
| **Geometric** | Spine curvature, head tilt, shoulder slope |
| **Angular** | Arm angles, shoulder asymmetry |
| **Velocity** | Movement speed, acceleration |
| **Derived** | Kinetic energy, stillness duration |

**Source:** `src/posture/features.py`

### Temporal Model: TCN-LSTM

```
Input: (batch, 30 frames, 15 features)
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ TCN Encoder  â”‚  Dilated convolutions
    â”‚ 64â†’128â†’256   â”‚  Multi-scale patterns
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    LSTM      â”‚  Temporal dependencies
    â”‚ Hidden: 128  â”‚  State: improving/deteriorating
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Projection  â”‚
    â”‚    512D      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Source:** `src/posture/temporal_model.py`

---

## 4. Fusion Engine

### Cross-Attention Mechanism

Allows each modality to attend to relevant parts of the other.

```python
# Facial features attend to posture
Q = FacialEmb @ W_query  
K = PostureEmb @ W_key
V = PostureEmb @ W_value
Attention = softmax(Q @ K.T / sqrt(d)) @ V
```

**Configuration:**
- Attention heads: 8
- Facial embed dim: 512
- Posture embed dim: 512
- Fused dim: 1024

**Source:** `src/fusion/fusion.py`

---

## 5. Prediction Heads

The classifier has **6 prediction heads** operating on the 1024D fused embedding:

| Head | Classes | Purpose |
|------|---------|---------|
| **Stress** | low, moderate, high | Overall stress level |
| **Depression** | minimal, mild, moderate, severe | Depression indicators |
| **Anxiety** | minimal, mild, moderate, severe | Anxiety indicators |
| **Posture** | upright, slouched, open, closed | Body language state |
| **Stress Indicator** | calm, fidgeting, restless, stillness | Movement patterns |
| **Trajectory** | stable, deteriorating, improving | Temporal trend |

**Uncertainty Estimation:**
- Monte Carlo Dropout (10 samples)
- Temperature scaling (1.5)

**Source:** `src/prediction/classifier.py`

---

## 6. File Structure

```
src/
â”œâ”€â”€ config.py                 # All configuration dataclasses
â”‚
â”œâ”€â”€ facial/
â”‚   â”œâ”€â”€ emotion.py            # EmotionClassifier (DenseNet121)
â”‚   â”œâ”€â”€ detector.py           # BlazeFace face detector
â”‚   â”œâ”€â”€ facemesh_analyzer.py  # MediaPipe FaceMesh 468 landmarks
â”‚   â”œâ”€â”€ postprocessor.py      # Emotion post-processing & temporal smoothing
â”‚   â””â”€â”€ action_units.py       # Action Unit detection
â”‚
â”œâ”€â”€ posture/
â”‚   â”œâ”€â”€ pose_estimator.py     # MediaPipe wrapper
â”‚   â”œâ”€â”€ features.py           # Feature extraction
â”‚   â””â”€â”€ temporal_model.py     # TCN-LSTM model
â”‚
â”œâ”€â”€ fusion/
â”‚   â””â”€â”€ fusion_network.py     # Cross-attention fusion
â”‚
â”œâ”€â”€ prediction/
â”‚   â”œâ”€â”€ classifier.py         # 6-head mental health classifier
â”‚   â”œâ”€â”€ heuristic.py          # Rule-based fallback
â”‚   â””â”€â”€ calibration.py        # Alert system
â”‚
â”œâ”€â”€ video/
â”‚   â””â”€â”€ capture.py            # Video capture utilities
â”‚
â””â”€â”€ visualization/
    â”œâ”€â”€ monitor.py            # Real-time monitoring dashboard
    â””â”€â”€ facemesh_visualizer.py # Face meshgrid overlay (468 landmarks)
```

---

## Configuration

All model parameters are configured in `src/config.py`:

```python
@dataclass
class FacialConfig:
    emotion_classes: List[str]  # 6 emotions
    embedding_dim: int = 1280
    
@dataclass
class PostureConfig:
    input_dim: int = 15         # 15 posture features
    tcn_channels: List[int] = [64, 128, 256]
    lstm_hidden_size: int = 128
    
@dataclass
class FusionConfig:
    facial_embed_dim: int = 512
    posture_embed_dim: int = 512
    fused_dim: int = 1024
    attention_heads: int = 8
```
